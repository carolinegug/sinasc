{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import os\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iniciando a sessão com spark\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master('local')\n",
    "    .appName(\"Pyspark_01\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINASC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura dos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o caminho do diretório onde estão os arquivos CSV\n",
    "diretorio = r'C:\\Users\\carol\\OneDrive\\Estudos\\MBA Data Science\\TCC\\SINASC\\Dados_SINASC'\n",
    "\n",
    "# Lista para armazenar os DataFrames de cada arquivo CSV\n",
    "dataframes = []\n",
    "\n",
    "# Percorre todos os arquivos no diretório\n",
    "for arquivo in os.listdir(diretorio):\n",
    "    if arquivo.endswith('.csv'):  # Verifica se o arquivo é um CSV\n",
    "        caminho_arquivo = os.path.join(diretorio, arquivo)\n",
    "        # Lê o arquivo CSV com o separador ';'\n",
    "        df = spark.read.option(\"header\", \"true\").csv(caminho_arquivo, sep=';')\n",
    "        # Remove a coluna \"CONTADOR\" ou \"contador\" do DataFrame, se existir\n",
    "        for coluna in df.columns:\n",
    "            if coluna.lower() == \"contador\":\n",
    "                df = df.drop(coluna)\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Define uma função para unir dois DataFrames preservando apenas as colunas de mesmo nome\n",
    "def merge_dfs(df1, df2):\n",
    "    # Seleciona as colunas comuns para ambas os DataFrames\n",
    "    colunas_comuns = [coluna for coluna in df2.columns if coluna in df1.columns]\n",
    "    # Seleciona as colunas comuns para ambos os DataFrames\n",
    "    df2 = df2.select(colunas_comuns)\n",
    "    # Realiza a união dos DataFrames\n",
    "    return df1.unionByName(df2)\n",
    "\n",
    "# Aplica a função de união em todos os DataFrames\n",
    "df_sinasc = reduce(merge_dfs, dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinasc.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conta o número de linhas no DataFrame\n",
    "num_linhas = df_sinasc.count()\n",
    "# Obtém o número de colunas no DataFrame\n",
    "num_colunas = len(df_sinasc.columns)\n",
    "# Exibe a quantidade de linhas e colunas\n",
    "print(f\"Quantidade de linhas: {num_linhas}\")\n",
    "print(f\"Quantidade de colunas: {num_colunas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinasc.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for coluna in df_sinasc.columns:\n",
    "#    print(coluna, df_sinasc.filter(df_sinasc[coluna].isNull()).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ORIGEM 0\n",
    "CODESTAB 197029\n",
    "CODMUNNASC 0\n",
    "LOCNASC 0\n",
    "IDADEMAE 235\n",
    "ESTCIVMAE 134793\n",
    "ESCMAE 134998\n",
    "CODOCUPMAE 4337117\n",
    "QTDFILVIVO 588584\n",
    "QTDFILMORT 929109\n",
    "CODMUNRES 0\n",
    "GESTACAO 282763\n",
    "GRAVIDEZ 23468\n",
    "PARTO 13558\n",
    "CONSULTAS 8937\n",
    "DTNASC 0\n",
    "HORANASC 21353\n",
    "SEXO 0\n",
    "APGAR1 344933\n",
    "APGAR5 345625\n",
    "RACACOR 610120\n",
    "PESO 5385\n",
    "IDANOMAL 188364\n",
    "DTCADASTRO 1166\n",
    "CODANOMAL 20350522\n",
    "NUMEROLOTE 21474\n",
    "VERSAOSIST 22154\n",
    "DTRECEBIM 72732\n",
    "DIFDATA 0\n",
    "DTRECORIGA 14126025\n",
    "NATURALMAE 350957\n",
    "CODMUNNATU 351799\n",
    "CODUFNATU 351799\n",
    "ESCMAE2010 270170\n",
    "SERIESCMAE 7445179\n",
    "DTNASCMAE 194067\n",
    "RACACORMAE 735202\n",
    "QTDGESTANT 633460\n",
    "QTDPARTNOR 859196\n",
    "QTDPARTCES 953151\n",
    "IDADEPAI 12770015\n",
    "DTULTMENST 10133444\n",
    "SEMAGESTAC 289627\n",
    "TPMETESTIM 289613\n",
    "CONSPRENAT 369974\n",
    "MESPRENAT 537813\n",
    "TPAPRESENT 209143\n",
    "STTRABPART 327999\n",
    "STCESPARTO 296096\n",
    "TPNASCASSI 165082\n",
    "TPFUNCRESP 774876\n",
    "TPDOCRESP 140325\n",
    "DTDECLARAC 314407\n",
    "ESCMAEAGR1 270170\n",
    "STDNEPIDEM 1595\n",
    "STDNNOVA 0\n",
    "CODPAISRES 2924761\n",
    "TPROBSON 0\n",
    "PARIDADE 0\n",
    "KOTELCHUCK 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecionando parte de colunas\n",
    "colunas_selecionadas = ['DTNASC','LOCNASC','CODMUNNASC','CODESTAB','SEXO','RACACOR','PESO','CODANOMAL','IDANOMAL','GESTACAO','SEMAGESTAC','GRAVIDEZ','TPAPRESENT','STTRABPART','STCESPARTO','PARTO','TPNASCASSI','IDADEMAE','ESTCIVMAE','RACACORMAE','ESCMAE','ESCMAE2010','ESCMAEAGR1','CODOCUPMAE','PARIDADE','QTDGESTANT','QTDFILVIVO','QTDFILMORT','QTDPARTNOR','QTDPARTCES','MESPRENAT','CONSULTAS','CONSPRENAT','KOTELCHUCK','TPROBSON','IDADEPAI']\n",
    "df_sinasc_fil = df_sinasc[colunas_selecionadas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinasc_fil.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conta o número de linhas no DataFrame\n",
    "num_linhas = df_sinasc_fil.count()\n",
    "# Obtém o número de colunas no DataFrame\n",
    "num_colunas = len(df_sinasc_fil.columns)\n",
    "# Exibe a quantidade de linhas e colunas\n",
    "print(f\"Quantidade de linhas: {num_linhas}\")\n",
    "print(f\"Quantidade de colunas: {num_colunas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinasc_fil.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformação de colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTNASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checando os anos disponíveis\n",
    "'''valores_distintos = df_sinasc_fil.select(substring(\"DTNASC\", -4, 4).alias(\"Primeiros_4_Caracteres_DT\")).distinct()\n",
    "valores_distintos = valores_distintos.orderBy(\"Primeiros_4_Caracteres_DT\")\n",
    "valores_distintos.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte a coluna 'DTNASC' para string e preenche com zeros à esquerda\n",
    "df_sinasc_fil = df_sinasc_fil.withColumn(\"DTNASC\", lpad(col(\"DTNASC\").cast(\"string\"), 8, '0'))\n",
    "df_sinasc_fil = df_sinasc_fil.withColumn(\"DTNASC\", to_date(col(\"DTNASC\"), \"ddMMyyyy\"))\n",
    "\n",
    "#poderíamos usar o seguinte código\n",
    "#df_sinasc_fil = df_sinasc_fil.withColumn(\"DTNASC\", to_date(lpad(col(\"DTNASC\").cast(\"string\"), 8, '0'), \"ddMMyyyy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria a coluna de ano\n",
    "df_sinasc_fil = df_sinasc_fil.withColumn(\"ano\", year(df_sinasc_fil[\"DTNASC\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODANOMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitui a letra X por nada na coluna 'CODANOMAL'\n",
    "df_sinasc_fil = df_sinasc_fil\\\n",
    "                .withColumn(\"CODANOMAL\", regexp_replace(col(\"CODANOMAL\"), \"X\", \"\"))\\\n",
    "                # Substitui 'Q356' por 'Q359' na coluna 'CODANOMAL'\n",
    "                .withColumn(\"CODANOMAL\", when(col(\"CODANOMAL\") == \"Q356\", \"Q359\").otherwise(col(\"CODANOMAL\")))\\\n",
    "                # Conta quantas letras possui no campo CODANOMAL e substitui valores nulos por 0\n",
    "                .withColumn(\"qt_anomal\", (col(\"CODANOMAL\").rlike(\"[a-zA-Z]\")).cast(\"int\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODESTAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinasc_fil = df_sinasc_fil.withColumn(\"CODESTAB\", col(\"CODESTAB\").cast(\"string\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação de novas colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiciona uma coluna de índice usando monotonically_increasing_id()\n",
    "#df_sinasc_fil = df_sinasc_fil.withColumn(\"indice\", monotonically_increasing_id())\n",
    "# Converte a coluna 'indice' para string\n",
    "#df_sinasc_fil = df_sinasc_fil.withColumn(\"indice\", df_sinasc_fil[\"indice\"].cast(\"string\"))\n",
    "df_sinasc_fil = df_sinasc_fil.withColumn(\"indice\", monotonically_increasing_id().cast(\"string\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ano_mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinasc_fil = df_sinasc_fil.withColumn(\"ano_mes\", date_format(\"DTNASC\", \"yyyy-MM\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### atualização colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novo_nome = {\n",
    "    'DTNASC': 'dt_nasc',\n",
    "    'LOCNASC': 'loc_nasc',\n",
    "    'CODMUNNASC': 'cod_mun_nasc',\n",
    "    'CODESTAB': 'cod_estab',\n",
    "    'SEXO': 'sexo',\n",
    "    'RACACOR': 'raca_cor',\n",
    "    'PESO': 'peso',\n",
    "    'CODANOMAL': 'cod_anomal',\n",
    "    'IDANOMAL': 'id_anomal',\n",
    "    'GESTACAO': 'gestacao',\n",
    "    'SEMAGESTAC': 'sema_gestac',\n",
    "    'GRAVIDEZ': 'gravidez',\n",
    "    'TPAPRESENT': 'tpa_present',\n",
    "    'STTRABPART': 'st_trab_parto',\n",
    "    'STCESPARTO': 'st_ces_parto',\n",
    "    'PARTO': 'parto',\n",
    "    'TPNASCASSI': 'tp_nasc_assi',\n",
    "    'IDADEMAE': 'idade_mae',\n",
    "    'ESTCIVMAE': 'est_civ_mae',\n",
    "    'RACACORMAE': 'raca_cor_mae',\n",
    "    'ESCMAE': 'esc_mae',\n",
    "    'ESCMAE2010': 'esc_mae_2010',\n",
    "    'ESCMAEAGR1': 'esc_mae_gr1',\n",
    "    'CODOCUPMAE': 'cod_ocup_mae',\n",
    "    'PARIDADE': 'paridade',\n",
    "    'QTDGESTANT': 'qtd_gestant',\n",
    "    'QTDFILVIVO': 'qtd_fil_vivo',\n",
    "    'QTDFILMORT': 'qtd_fil_mort',\n",
    "    'QTDPARTNOR': 'qtd_part_nor',\n",
    "    'QTDPARTCES': 'qtd_part_ces',\n",
    "    'MESPRENAT': 'mes_pre_nat',\n",
    "    'CONSULTAS': 'consultas',\n",
    "    'CONSPRENAT': 'cons_pre_nat',\n",
    "    'KOTELCHUCK': 'kotelchuck',\n",
    "    'TPROBSON': 'tp_robson',\n",
    "    'IDADEPAI': 'idade_pai'\n",
    "}\n",
    "\n",
    "for antigo_nome, novo_nome in novo_nome.items():\n",
    "    df_sinasc_fil = df_sinasc_fil.withColumnRenamed(antigo_nome, novo_nome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinasc_fil.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinasc_fil.groupBy(\"ano\")\\\n",
    "            .count().orderBy(\"ano\")\\\n",
    "            .withColumnRenamed(\"count\", \"qt_linhas\")\\\n",
    "            .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando colunas float que na verdade são string\n",
    "colunas_float = ['raca_cor', 'cod_anomal', 'id_anomal', 'gestacao', 'gravidez', 'tpa_present', 'st_trab_parto', 'st_ces_parto', 'parto', 'tp_nasc_assi', 'est_civ_mae', 'raca_cor_mae', 'esc_mae', 'esc_mae_2010', 'cod_ocup_mae', 'qtd_gestant', 'qtd_fil_vivo', 'qtd_fil_mort', 'qtd_part_nor', 'qtd_part_ces', 'mes_pre_nat', 'consultas', 'cons_pre_nat', 'sema_gestac']\n",
    "\n",
    "for coluna in colunas_float:\n",
    "     df_sinasc_fil = df_sinasc_fil.withColumn(coluna, regexp_replace(col(coluna), \"\\\\.0\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando coluna que está como float mas é int\n",
    "#coluna_int = ['idade_mae', 'idade_pai']\n",
    "#for coluna_nome in coluna_int:\n",
    "#   df_sinasc_fil = df_sinasc_fil.withColumn(coluna_nome, df_sinasc_fil[coluna_nome].fillna(0).cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinasc_fil.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#caminho_csv = r'C:\\Users\\carol\\OneDrive\\Estudos\\MBA Data Science\\TCC\\SINASC\\sinasc_compilado.csv'\n",
    "#df_sinasc_fil.write.csv(caminho_csv, header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FATO ANOMALIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando lista distinta de cod_anomal\n",
    "df_cod_anomal_sep = df_sinasc_fil\\\n",
    "    .select(\"cod_anomal\")\\\n",
    "    .distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a partir da cod_anomal distinta vamos segmentar os valores que possuem mais de um cod_anomal em uma nova coluna e depois quebrar isso para linhas\n",
    "df_cod_anomal_sep = df_cod_anomal_sep\\\n",
    "                    .withColumn(\"cod_anomal_sep\", split(col(\"cod_anomal\"), r\"(?<=\\d)(?=[a-zA-Z])\"))\\\n",
    "                    .select(col(\"cod_anomal\"), explode(col(\"cod_anomal_sep\")).alias(\"cod_anomal_sep\"))\\\n",
    "                    .filter(col(\"cod_anomal_sep\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cod_anomal_sep.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conta o número de linhas no DataFrame\n",
    "num_linhas = df_cod_anomal_sep.count()\n",
    "# Obtém o número de colunas no DataFrame\n",
    "num_colunas = len(df_cod_anomal_sep.columns)\n",
    "# Exibe a quantidade de linhas e colunas\n",
    "print(f\"Quantidade de linhas: {num_linhas}\")\n",
    "print(f\"Quantidade de colunas: {num_colunas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cod_anomal_sep.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvando CSV da base tratada\n",
    "#caminho_csv = r'C:\\Users\\carol\\OneDrive\\Estudos\\MBA Data Science\\TCC\\SINASC\\cod_anomal_sep.csv'\n",
    "#df_cod_anomal_sep.write.csv(caminho_csv, header=True, mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
